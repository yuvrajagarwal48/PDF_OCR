# # -*- coding: utf-8 -*-
# """OCR.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1IqM7jIC9EncA0RYUqkEriJXKeWwUKVIr
# """

# !pip install ultralytics --quiet

# !pip install paddleocr --upgrade --quiet
# !pip install paddlepaddle --quiet

# !apt-get install libnss3 libnss3-dev --quiet
# !apt-get install libcairo2-dev libjpeg-dev libgif-dev --quiet
# !apt-get install cmake libblkid-dev e2fslibs-dev libboost-all-dev libaudit-dev --quiet

# !apt-get install poppler-utils --quiet

# !pip install pdf2image --quiet

import numpy as np
import matplotlib.pyplot as plt
import cv2
from PIL import Image
from pdf2image import convert_from_path
from ultralytics import YOLO
import torch
import tensorflow as tf
import json
from paddleocr import PaddleOCR,draw_ocr
import time
from flask import Flask, request, jsonify

def grayscale_image(image):
    # Convert the image to grayscale
    grayscale_image = image.convert('L')
    return grayscale_image

def pdf_to_images(pdf_path):
    grayscaled_pil_images = []
    # Convert PDF to a list of PIL images
    images = convert_from_path(pdf_path, dpi=500)#, poppler_path =r'/usr/bin' )
    for img in images:
        gray_image = grayscale_image(img)
        grayscaled_pil_images.append(gray_image)
    return grayscaled_pil_images

def padding(x1,y1,x2,y2,padding=10):
    x1_pad = x1 - padding
    y1_pad = y1 - padding
    x2_pad = x2 + padding
    y2_pad = y2 + padding
    return [int(x1_pad), int(y1_pad), int(x2_pad), int(y2_pad)]

def image_localization(images):
  model=YOLO('/content/best.pt')
  cropped_images=[]
  for image in images:
    # plt.imshow(np.array(image))
    pil_image_array = np.array(image)
    image_cv = cv2.cvtColor(pil_image_array, cv2.COLOR_RGB2BGR)
    # image_cv=cv2.imread(image)
    results = model(image_cv)
    for result in results:
      boxes=result.boxes
      for box in boxes:
        x1,y1,x2,y2=box.xyxy[0].cpu().numpy()
        x1_pad,y1_pad,x2_pad,y2_pad=padding(x1,y1,x2,y2)
        cropped_image = image_cv[y1_pad:y2_pad, x1_pad:x2_pad]
        crop_img = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(crop_img)
        cropped_images.append(img_pil)
  return cropped_images

def intersection(box_1, box_2):
  return [box_2[0], box_1[1],box_2[2], box_1[3]]

def iou(box_1, box_2):

  x_1 = max(box_1[0], box_2[0])
  y_1 = max(box_1[1], box_2[1])
  x_2 = min(box_1[2], box_2[2])
  y_2 = min(box_1[3], box_2[3])

  inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))
  if inter == 0:
      return 0

  box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))
  box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))

  return inter / float(box_1_area + box_2_area - inter)

def image_to_text(images):
  outputs=[]
  ocr=PaddleOCR(lang='en')
  for image in images:
    pil_image_array = np.array(image)
    # Convert RGB to BGR (OpenCV uses BGR by default)
    image_cv = cv2.cvtColor(pil_image_array, cv2.COLOR_RGB2BGR)
    output=ocr.ocr(image_cv)
    boxes = [line[0] for line in output[0]]
    texts = [line[1][0] for line in output[0]]
    probabilities = [line[1][1] for line in output[0]]
    image_height = image_cv.shape[0]
    image_width = image_cv.shape[1]
    image_boxes = image_cv.copy()
    im = image_cv.copy()
    horiz_boxes = []
    vert_boxes = []

    for box in boxes:
      x_h, x_v = 0,int(box[0][0])
      y_h, y_v = int(box[0][1]),0
      width_h,width_v = image_width, int(box[2][0]-box[0][0])
      height_h,height_v = int(box[2][1]-box[0][1]),image_height

      horiz_boxes.append([x_h,y_h,x_h+width_h,y_h+height_h])
      vert_boxes.append([x_v,y_v,x_v+width_v,y_v+height_v])

      cv2.rectangle(im,(x_h,y_h), (x_h+width_h,y_h+height_h),(0,0,255),1)
      cv2.rectangle(im,(x_v,y_v), (x_v+width_v,y_v+height_v),(0,255,0),1)
    #Horizontal Lines
    horiz_out = tf.image.non_max_suppression(
    horiz_boxes,
    probabilities,
    max_output_size = 1000,
    iou_threshold=0.1,
    score_threshold=float('-inf'),
    name=None
    )
    horiz_lines = np.sort(np.array(horiz_out))
    #Vertical Lines
    vert_out = tf.image.non_max_suppression(
    vert_boxes,
    probabilities,
    max_output_size = 1000,
    iou_threshold=0.1,
    score_threshold=float('-inf'),
    name=None
    )
    vert_lines = np.sort(np.array(vert_out))

    out_array = [["" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]
    unordered_boxes = []
    for i in vert_lines:
      unordered_boxes.append(vert_boxes[i][0])
    ordered_boxes = np.argsort(unordered_boxes)
    for i in range(len(horiz_lines)):
      for j in range(len(vert_lines)):
        resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]] )
        for b in range(len(boxes)):
          the_box = [boxes[b][0][0],boxes[b][0][1],boxes[b][2][0],boxes[b][2][1]]
          if(iou(resultant,the_box)>0.1):
            out_array[i][j] = texts[b]
    out_array=np.array(out_array)
    outputs.append(out_array)
  return np.array(outputs)

def jsonify(outputs):
    output_json = []

    for output in outputs:
        dict_list = []

        for item in output:
            jdict = {
                str(i): item[i] for i in range(len(item))
            }
            dict_list.append(jdict)

        output_json.append(dict_list)

    return json.dumps(output_json, indent=4)

def OCR(input,flag):
  if(flag==1):    #If the input is pdf
    images=pdf_to_images(input)
  else:           #If the input is image
    images=input
  cropped_images=image_localization(images)
  outputs=image_to_text(cropped_images)
  json_file=jsonify(outputs)
  return json_file

json1=OCR('pdf1.pdf')

print(json)

# app = Flask(__name__)

# @app.route("/ocr/pdf", methods=["POST"])
# def ocr_pdf():
#     file = request.files['file']
#     if file.filename == '':
#         return jsonify({'error': 'No selected file'}), 400
#     if file:
#         try:
#             # Save the PDF file temporarily
#             file_path = "/tmp/temp.pdf"
#             file.save(file_path)
#             # Perform OCR on the PDF
#             images = pdf_to_images(file_path)
#             cropped_images = image_localization(images)
#             outputs = image_to_text(cropped_images)
#             json_file = jsonify(outputs)
#             return json_file
#         except Exception as e:
#             return jsonify({'error': str(e)}), 500

# if __name__ == "__main__":
#     app.run()
    
    
    
# %%time
# OCR('/content/pdf1.pdf',1)
